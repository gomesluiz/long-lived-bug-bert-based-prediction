\section{Introduction}\label{chapter:4:sec:introduction}

\textcolor{red}{ISSUES: 1.3, 1.5 - randomizing categorization of bugs into short-lived and long-lived}
Today's software maintenance activities in Free/Libre Open Source Software~(FLOSS) and Closed Source Software~(CSS) rely mainly on information extracted from bug reports opened in a Bug Tracking Systems (BTS). This kind of system plays a key role as a communication and collaboration tool in both environments.  However, with many users and developers with different expertise and spread out worldwide, FLOSS increased the requirement of using a BTS in the maintenance pipeline.
   
Users and developers interact with the maintenance team filling out a short description, a long description, and provisional severity level associated with a bug in a bug report form provided by a BTS. Next, a maintenance team member  reviews the bug report and either approve or reject it. If the bug report is approved, the team member provides more information, such as indicating its priority and assigning a person in charge for fixing it. Due to the high number of bug reports in medium- and large-size FLOSS projects~\cite{Yang:2017}, the manual handling of bug reports may be entirely subjective, tiresome, and error-prone.  \textcolor{red}{ISSUES: 1.6 - support this statement} Therefore, a wrong decision within the bug report lifecycle may strongly affect the planning of maintenance activities. 

Estimating fixing times and the immediate identification of opened bugs that may have a long-lived lifecycle are essential for maintenance teams to build their plan. With that, managers may improve the resource allocation and better create a release roadmap avoiding the bugs backlog overgrow ~\cite{Abdelmoez:2012, Zhang:2013, Ardimento:2016, Ardimento_Dinapoli:2017, Abbood:2017, Akbarinasaji:2018, Sepahvand:2020}. Also, the correct prediction of long-lived bugs may help the quality assurance team improve their daily activities. \textcolor{red}{ISSUES: 1.7 - support this statement} They could fix more bugs that often adversely affect software quality and disturb the user experience across versions of FLOSS, which may increase customers' satisfaction, avoiding them to switch in favor of a competitor~\cite{Rawal:2015, Saha:2015b, Mezouar:2018, Akbarinasaji:2018}.

Machine Learning~(ML) and Text Mining~(TM) techniques have been successfully applied to solve many real-world prediction problems, including those related to automating bug report handling, such as bug severity prediction~\cite{Singh:2017, Roy:2017, gomes:2019, Saha:2015b, Rocha:2016, gomes:2021}. Recent advances in Natural Language Processing (NLP) have shifted the research focus from traditional techniques to deep-learning-based techniques. Bidirectional Encoder Representations from Transformers (BERT), a deep neural learning network for NLP, have recently surpassed classical text mining approaches in various text classification tasks~\cite{Devlin:2019, Gonzalez:2020, sun:2020}. There are two approaches to adapt BERT for particular tasks: feature extraction and fine-tuning. The first method freezes model weights, and the pre-trained representations are used in a downstream model like standard feature-based approaches. On the other hand, in the second method, the pre-trained model can be unfrozen and fine-tuned on a new task~\cite{Peters:2019}.

\textcolor{red}{ISSUES: 2.2, 2.3: cite other papers that investigate long-lived bugs and better motivate the our research}
To the best of our knowledge, few studies investigated the use of BERT and the effect of its contextual embedding in Software Engineering tasks, such as long-lived bug prediction~\cite{ardimento:2020} or sentiment analysis~\cite{Batra:2021, Biswas:2020, Wu:2021}. Ardimento et al.~\cite{ardimento:2020}, for instance, yielded relevant results in their experiment using fine-tuning in this prediction task. However, they carried out their investigation on only one dataset extracted from LiveCode BTS with a relatively small number of bug reports.  Still, performed experiments described in their paper were not deeply detailed. 


In this paper, we investigate the use of BERT-based feature extractor for long-lived bug prediction. Furthermore, we compared the accuracy performance of model predictors on six popular FLOSS projects, using feature extraction based on BERT or TF-IDF. Finally, we characterized the bugs correctly and incorrectly predicted as long-lived bugs. In short, our specific goal is: 

\begin{quote}
  {\it Evaluate the long-lived prediction accuracy of five well-known machine learning classifiers when using BERT and TF-IDF as feature extractor}
\end{quote}

This specific goal leads to the definition of the following Research Questions (RQs) addressed in our study:

\begin{enumerate}[label=\textbf{RQ$_{\arabic*}$}.]\addtocounter{enumi}{0}

    \item {\it What is the comparative accuracy of ML classifiers when predicting long-lived bugs using BERT-based feature extraction?}~We aim to compare the accuracy of long-lived bug prediction systems based on different classifiers when BERT features are used. Answering this research question is essential for understanding the impact of contextual embedding features provided by BERT on the accuracy of traditional ML classifiers.
    
    \item {\it What is the comparative accuracy of ML classifiers when predicting long-lived bugs using BERT-based feature extraction or TF-IDF-based feature extraction?}~We aim to compare the accuracy of long-lived bug prediction systems when different feature extractors, based on BERT and TF-IDF, are employed. Answering this research question provides insights related to the choice of suitable features for automating the prediction of long-lived bugs with high accuracy.
    
    \item {\it What are the main characteristics of bugs correctly predicted as long-lived (True Positive) and incorrectly predicted as short-lived (False Negative) when using BERT- or TF-IDF-based feature extraction?}~Even if our long-lived prediction models do not correctly predict many long-lived bugs, investigating the characteristics of those with high and low accuracy  is expected to open new opportunities for further research towards improving the prediction models.
  
\end{enumerate}

\textcolor{red}{ISSUES: 1.1 - lacking of novelty compared to previous work; 3.2 - The paper's formulation of the classification problem is merely an application of text classification to bug reports.}
The contributions of this paper can be summarized as follows:
\begin{itemize}
  \item A quantitative assessment of the performance of traditional ML classifiers using features extracted with BERT for the long-lived bug prediction atsn;
  \item A quantitative performance comparison between BERT and TF-IDF for extracting features on the long-lived prediction task; and
  \item Discussion upon qualitative characteristics associated with bugs correctly and incorrectly classified as long-lived.
\end{itemize}

The paper is organized as follows.  
Section~\ref{chapter:4:sec:terminology} provides background concepts related to bug tracking systems, text mining, and machine learning techniques. Section~\ref{chapter:4:sec:related} presents related work. Section~\ref{chapter:4:sec:methodology} describes the methodology used. Section~\ref{chapter:4:sec:results} reports our results. Section~\ref{chapter:4:sec:discussions} describes the significance of our findings and how they can be interpreted. Section \ref{chapter:4:sec:validity} describes the main threats to the validity of our research. Finally, Section~\ref{chapter:4:sec:conclusion} states our conclusions and highlights possible future research associated with our findings.
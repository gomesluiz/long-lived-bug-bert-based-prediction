\section{Introduction}\label{chapter:4:sec:introduction}

Today's software maintenance activities in Free/Libre Open-Source Software~(FLOSS) and Closed Source Software~(CSS) rely mainly on information extracted from bug reports opened in a Bug Tracking Systems (BTS). This kind of system plays a key role as a communication and collaboration tool in both environments. However, with many users and developers with different expertise and spread out worldwide, FLOSS increased the requirement of using a BTS in the maintenance pipeline.

Users and developers often interact with the maintenance team filling out a brief description, a long description, and provisional severity level associated with a bug in a bug report form provided by a BTS. Next, a maintenance team member  reviews the bug report and either approve or reject it. If a team member approves the bug report, he or she provides further information, such as indicating its priority and assigning a person in charge of fixing it. Due to the high number of bug reports in medium- and large-size FLOSS projects, the manual handling of bug reports may be entirely subjective, tiresome, and error-prone~\cite{Lamkanfi:2010, Lamkanfi:2011, Yang:2017}. Therefore, a wrong decision within the bug report lifecycle may strongly affect the planning of maintenance activities.

Estimating fixing times and the immediate identification of opened bugs that may have a long-lived lifecycle are essential for maintenance teams to build their plan. With that, managers may improve the resource allocation and better create a release roadmap, avoiding the bugs backlog overgrow~\cite{Abdelmoez:2012, Zhang:2013, Ardimento:2016}. Furthermore, the correct prediction of long-lived bugs may help the quality assurance team improve their daily activities~\cite{Ardimento_Dinapoli:2017, Abbood:2017, Akbarinasaji:2018, Sepahvand:2020}. They could fix more bugs that often adversely affect software quality and disturb the user experience across versions of FLOSS, which may increase customers' satisfaction, avoiding them to switch in favor of a competitor~\cite{Rawal:2015, Saha:2015b, Mezouar:2018, Akbarinasaji:2018}.

In the literature, despite its importance, it seems there is not a common understanding about what is a long-live bug~\cite{saha:2014, Saha:2015, Saha:2015b,gomes:2021}. While some authors~\cite{Canfora:2011, Marks:2011, saha:2014, Saha:2015b} consider absolute values as thresholds (based on the release cycle), others~\cite{Abdelmoez:2012, Giger:2010, Francis_Williams:2013, Ardimento:2016, Ardimento_Dinapoli:2017, Sepahvand:2020} consider threshold values based on the statistical distribution of bug-fixing times for each FLOSS project. These different visions may suggest that the definition of the long-live threshold is related to particular characteristics of each project (e.g., size of the team). \done{Despite this fact, we adopted a conservative one-year threshold that covers at least one cycle of most  projects~\cite{saha:2014, Saha:2015, Saha:2015b}. Hence, we can safely classify a bug as long-lived if it survived for more than one year (threshold value). Second, such threshold (one year) enables us to compare the population of long-lived bugs independently and uniformly considering different projects.}

Machine Learning~(ML) and Text Mining~(TM) techniques have solved many real-world prediction problems, including those related to automating bug report handling, such as bug severity prediction~\cite{Singh:2017, Roy:2017, gomes:2019, Saha:2015b, Rocha:2016, gomes:2021}. Advances in Natural Language Processing~(NLP) have shifted the research focus from traditional to deep-learning-based techniques. Bidirectional Encoder Representations from Transformers (BERT), a deep neural learning network for NLP, have recently surpassed classical text mining approaches in various text classification tasks~\cite{Devlin:2019, Gonzalez:2020, sun:2020}. There are two approaches to adapt BERT for particular tasks: feature extraction and fine-tuning. The first method freezes model weights, and the pre-trained representations are used in a downstream model like standard feature-based approaches. In the second method, in turn, the pre-trained model can be unfrozen and fine-tuned on a new task~\cite{Peters:2019}.

There are broad research efforts toward the use of BERT and the effect of its contextual embedding in Software Engineering tasks~\cite{csuvik:2020, feng:2020, guo:2020, kanade:2020, wang:2020, akimova:2021, allamanis:2021, dearaujo:2021, jinfeng:2021, wang:2021, zou:2021}. Even so, to the best of our knowledge, few studies applied it in long-lived bug prediction task~\cite{ardimento:2020}. Ardimento et al.~\cite{ardimento:2020}, for instance, yielded relevant results in their experiment using fine-tuning in this prediction task. However, they carried out their investigation on only one dataset extracted from LiveCode BTS with a relatively small number of bug reports. 

In this paper, we investigate the use of BERT-based feature extractors and a fine-tuning approach for long-lived bug prediction. Furthermore, we compare their accuracy with the traditional TF-IDF on six popular FLOSS projects. In this context, we evaluate the long-lived prediction accuracy of five well-known machine learning classifiers when using BERT and TF-IDF as feature extractor or BERT fine-tuning.

\vspace{0.15cm}
This specific goal leads to the definition of the following Research Questions~(RQs) addressed in our study:
\vspace{0.15cm}
\begin{enumerate}
    \item \done{How accurate are ML classifiers when it uses BERT as features extractor in predicting long-lived bugs?} 

    \item \done{What is the comparative accuracy of ML classifiers when predicting long-lived bugs using BERT-based feature extraction or TF-IDF-based feature extraction?}

    \item \done{Are smaller BERT variants with fine-tuning better than feature extraction method for long-lived bug prediction?}

\end{enumerate}

\vspace{0.15cm}
The contributions of this paper can be summarized as follows:
\vspace{0.15cm}
\begin{itemize}
  \item \done{Evaluation of tradition ML classifiers accuracy when they used features extracted with BERT for the long-lived bug prediction;}
  \item A quantitative accuracy comparison between BERT and TF-IDF for extracting features on the long-lived prediction task; 
  \item \done{Evaluation of the BERT fine-tuning and smaller BERT variants impact on accuracy in the long-lived prediction task.}
\end{itemize}

We organized the paper as follows.  
Section~\ref{chapter:4:sec:terminology} provides background concepts related to bug tracking systems, text mining, and machine learning techniques. Section~\ref{chapter:4:sec:related} presents related work. Section~\ref{chapter:4:sec:methodology} describes the methodology used. Section~\ref{chapter:4:sec:results} reports our results. Section~\ref{chapter:4:sec:discussions} describes the significance of our findings and how they can be interpreted. Section \ref{chapter:4:sec:validity} describes the main threats to the validity of our research. Finally, Section~\ref{chapter:4:sec:conclusion} states our conclusions and highlights possible future research associated with our findings.